{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c774777",
   "metadata": {},
   "source": [
    "# 前深度学习时代"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4fad1",
   "metadata": {},
   "source": [
    "- 协同过滤CF\n",
    "- 逻辑回归LR\n",
    "- 因子分解机FM\n",
    "- 梯度提升树GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70078b1a",
   "metadata": {},
   "source": [
    "![截屏2022-06-30 21.32.27](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202206302132104.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba730fab",
   "metadata": {},
   "source": [
    "**协同过滤**\n",
    "- UserCF 用户协同过滤\n",
    "- ItemCF 物品协同过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0783b",
   "metadata": {},
   "source": [
    "提升处理稀疏矩阵的能力引入矩阵分解模型MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe0488",
   "metadata": {},
   "source": [
    "**逻辑回归模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fd681",
   "metadata": {},
   "source": [
    "**因子分解机器模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73a2df",
   "metadata": {},
   "source": [
    "在逻辑回归模型上加入了二阶部分，使模型具备了特征组合的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a45c4",
   "metadata": {},
   "source": [
    "**组合模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf1f7c",
   "metadata": {},
   "source": [
    "## 协同过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b59a8",
   "metadata": {},
   "source": [
    "**“协同过滤”**就是协同大家的反馈、评价和意见一起对 海量的信息进行过滤，从中筛选出目标用户可能感兴趣的信息的推荐 过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bc9cf",
   "metadata": {},
   "source": [
    "#### UserCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37633d5",
   "metadata": {},
   "source": [
    "找到topN用户与需要预测的用户兴趣最为相似。然后通过相似用户的兴趣对需要预测的用户进行预测。\n",
    "- cosine similar 余弦相似度\n",
    "- 皮尔逊相关系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411cf8a",
   "metadata": {},
   "source": [
    "**缺点**：\n",
    "- 用户数大于物品数，开销大\n",
    "- 用户的历史数据向量往往非常稀疏，这导致 UserCF 不适用于那些正反馈获取较困难的应用场景(如酒店预定、大件商 品购买等低频应用)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de624a",
   "metadata": {},
   "source": [
    "#### ItemCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de354dc",
   "metadata": {},
   "source": [
    "ItemCF 是基于物品相似度进行推荐的协同过滤算法。 通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵， 再找到用户的历史正反馈物品的相似物品进行进一步排序和推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b1a97",
   "metadata": {},
   "source": [
    "#### 总结\n",
    "- UserCF: 基于用户相似度进行推荐，使其具备更强的社交特性.用户能够快速得知与自己兴趣相似的人最近喜欢的是什 么\n",
    "- ItemCF: 更适用于兴趣变化较为稳定的应用\n",
    "- 缺点：推荐结果的头部效应较明显，处理稀疏向量的能力弱\n",
    "- 解决办法：矩阵分解技术：该方法在协同过滤共现矩阵的基础上，使用更稠密的隐向量表示 用户和物品，挖掘用户和物品的隐含兴趣和隐含特征，在一定程度上 弥补了协同过滤模型处理稀疏矩阵能力不足的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364a633",
   "metadata": {},
   "source": [
    "## 矩阵分解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090356c1",
   "metadata": {},
   "source": [
    "矩阵分解算法则期望为每一个用户和视频生成一个隐向量，将用 户和视频定位到隐向量的表示空间上，距离相 近的用户和视频表明兴趣特点接近，在推荐过程中，就应该把距离相 近的视频推荐给目标用户"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be5f4b",
   "metadata": {},
   "source": [
    "矩阵分解算法将m×n维的共现矩阵R分解为m×k维的用户矩阵U和k× n维的物品矩阵V相乘的形式。其中m是用户数量，n是物品数量，k是隐 向量的维度。k 的大小决定了隐向量表达能力的强弱。**k 的取值越小， 隐向量包含的信息越少，模型的泛化程度越高;反之，k 的取值越大，隐向量的表达能力越强，但泛化程度相应降低**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee9727",
   "metadata": {},
   "source": [
    "#### 矩阵分解方法\n",
    "- 特征值分解（只能方阵）\n",
    "- 奇异值分解 SVD, 传统奇异值分解的计算复杂度达到O(mn2)\n",
    "- 梯度下降 **主要方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d81321",
   "metadata": {},
   "source": [
    "**优点：**\n",
    "- 泛化能力强\n",
    "- 空间复杂度低\n",
    "- 更好的扩展性和灵活性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654e2bc",
   "metadata": {},
   "source": [
    "矩阵分解的最终产出是用户和物品 隐向量，这其实与深度学习中的Embedding思想不谋而合，因此矩阵分 解的结果也非常便于与其他特征进行组合和拼接，并便于与深度学习 网络进行无缝结合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe136b96",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d119f6",
   "metadata": {},
   "source": [
    "逻辑回归将推荐问题看成一个分类问题，通过预测正样本的概率对物品进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7ed91",
   "metadata": {},
   "source": [
    "因此，逻辑回归模型将推荐问题转换成了一个点击率(Click Through Rate，CTR)预估问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c4a486",
   "metadata": {},
   "source": [
    "**逻辑回归模型**\n",
    "![截屏2022-06-30 22.39.32](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202206302239582.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d8e76",
   "metadata": {},
   "source": [
    "目标函数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3028941",
   "metadata": {},
   "source": [
    "![截屏2022-06-30 22.44.38](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202206302244520.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a031b",
   "metadata": {},
   "source": [
    "缺点：表达能力不强，无法进行特征交 叉、特征筛选等一系列较为“高级”的操作，因此不可避免地造成信息 的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1729a",
   "metadata": {},
   "source": [
    "解决：因子分解机，多层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a297a2",
   "metadata": {},
   "source": [
    "## FM到FFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515256f1",
   "metadata": {},
   "source": [
    "逻辑回归只对单一特征做简单加权，不具备进行特征交叉生成高 维组合特征的能力，因此表达能力很弱，甚至可能得出像“辛普森悖 论”那样的错误结论"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a34c9a",
   "metadata": {},
   "source": [
    "**POLY2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06156081",
   "metadata": {},
   "source": [
    "POLY2 通过暴力组合特征的方式，在一定程度上解决了特征组合的问题\n",
    "![截屏2022-06-30 22.52.32](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202206302252331.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49363b",
   "metadata": {},
   "source": [
    "缺点：维度大，难以训练，很难收敛。权重参数的数量由n直接上升到n2，极大地增加了训练复杂 度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc975a4a",
   "metadata": {},
   "source": [
    "**FM因子分解机器**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419c54b",
   "metadata": {},
   "source": [
    "与POLY2相比，其主要区别是用两个向量的内积，取代了单一的权重系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0631dfe2",
   "metadata": {},
   "source": [
    "![截屏2022-06-30 22.56.06](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202206302256731.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7990a",
   "metadata": {},
   "source": [
    "FM为每个特征学习了一个隐权重向量(latent vector)。在特 征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。维度从n2 降级到 nk (k为向量维度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cdc64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
