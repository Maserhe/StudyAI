{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75abef51",
   "metadata": {},
   "source": [
    "# DL深度学习\n",
    "- Deep Crossing\n",
    "- Wide & Deep\n",
    "- FNN\n",
    "- PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab91c6",
   "metadata": {},
   "source": [
    "**优势：**\n",
    "- 与传统的机器学习模型相比，深度学习模型的表达能力更 强，能够挖掘出更多数据中潜藏的模式\n",
    "- 深度学习的模型结构非常灵活，能够根据业务场景和数据特 点，灵活调整模型结构，使模型与应用场景完美契合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb832d40",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 14.19.05](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011419975.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57aee6d",
   "metadata": {},
   "source": [
    "**演化方式**\n",
    "- 改变神经网络的复杂程度 Deep Crossing\n",
    "- 改变特征交叉方式 PNN, NeuralCF\n",
    "- 组合模型 Deep & Cross, DeepFM\n",
    "- FM 模型的深度学习演化版本 NFM、 FNN、 AFM\n",
    "- 注意力机制与推荐模型的结合 DIN\n",
    "- 序列模型与推荐模型的结合 DIEN\n",
    "- 强化学习与推荐模型的结合 DRN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc7eab",
   "metadata": {},
   "source": [
    "## AutoRe单隐层神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160ae13",
   "metadata": {},
   "source": [
    "网络的输入层是物品的 评分向量 r，输出层是一个多分类层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44fc4f",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 16.28.13](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011628103.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928ac12",
   "metadata": {},
   "source": [
    "- 输入：一个物品 i 来说，所有 m 个用户对它的评分可形成一个 m 维的向量r(i)\n",
    "- 输出：所有用户对物品 i 的评分 预测。那么，其中的第 u维就是用户u对物品i的预测  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8141989",
   "metadata": {},
   "source": [
    "跟协同过滤类似分为：\n",
    "- Item-AutoRec:\n",
    "- User-AutoRec:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa758d",
   "metadata": {},
   "source": [
    "问题：使用一个单隐层的 AutoEncoder泛化用户或物品评分，使模型具有一定的泛化和表达能力。由于AutoRec模型的结构比较简单，使其存在一定的表达能力不足的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947379a7",
   "metadata": {},
   "source": [
    "**词向量模型Word2vec**， 和 AutoRec模型一样。训练方法和优化目标有区别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa97690",
   "metadata": {},
   "source": [
    "## Deep Crossing模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4010b",
   "metadata": {},
   "source": [
    "特征分为三类：\n",
    "- **类别性特征**：搜索词，广告标题\n",
    "- **计数性特征**：点击率，预估点击率\n",
    "- **需要进一步处理的特征**： 曝光样例、点击样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd3761",
   "metadata": {},
   "source": [
    "问题：\n",
    "- 稀疏特征稠密化\n",
    "- 如何解决特征自动交叉组合的问题\n",
    "- 如何在输出层中达成问题设定的优化目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff937f1b",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 17.36.49](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011736522.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca8857",
   "metadata": {},
   "source": [
    "- Embedding 层： 将稀疏的类别型特征转换 成稠密的Embedding向量\n",
    "- Stacking 层：是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特 征向量，该层通常也被称为连接(concatenate)层\n",
    "- Multiple Residual Units层： 该层的主要结构是多层感知机，相比 标准的以感知机为基本单元的神经网络\n",
    "- Scoring层:Scoring层作为输出层，就是为了拟合优化目标而存在的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3d26a",
   "metadata": {},
   "source": [
    "## NeuralCF模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3fbd7",
   "metadata": {},
   "source": [
    "NeuralCF 用“多层神经网络+输出层”的结构替代了 矩阵分解模型中简单的内积操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e83da",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 18.16.25](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011816417.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62c8c0",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 18.27.52](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011827743.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc298d3",
   "metadata": {},
   "source": [
    "NeuralCF模型实际上提出了一个模型框架，它基于用户向量和物 品向量这两个Embedding层，利用不同的互操作层进行特征的交叉组 合，并且可以灵活地进行不同互操作层的拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b1c23",
   "metadata": {},
   "source": [
    "缺点：由于是基于协同过滤的思想进行构 造的，所以NeuralCF模型并没有引入更多其他类型的特征，这在实际 应用中无疑浪费了其他有价值的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d63bb",
   "metadata": {},
   "source": [
    "## PNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef03c08",
   "metadata": {},
   "source": [
    "PNN模型在 输入、Embedding层、多层神经网络，以及最终的输出层部分并没有结 构上的不同，**唯一的区别在于 PNN模型用乘积层(Product Layer)代 替了Deep Crossing模型中的Stacking层**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc0018",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 18.31.50](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011831383.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a7b4a",
   "metadata": {},
   "source": [
    "**亮点：乘积层**： 内积和外积的操作部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76002d7f",
   "metadata": {},
   "source": [
    "- 内积：假设输入特征向量分别为fi ， fj，特征的内积互操作Ginner(fi，fj)的定义\n",
    "- 外积：特征向量fi，fj各维度两两交叉而成的一个M× M的方形矩阵(其中M是输入向量的维度)。这样的外积操作无疑会直 接将问题的复杂度从原来的M提升到M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a09a12",
   "metadata": {},
   "source": [
    "**PNN模型在经过对特征的内积和外积互操作后，并没有 把结果直接送入上层的 L1 全连接层，而是在乘积层内部又进行了局部 全连接层的转换，分别将内积部分 z，外积部分 p 映射成了 D1维的输 入向量 Lz和 Lp**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6719e01",
   "metadata": {},
   "source": [
    "- 优势：相比于简单的交由全连接层进行无差别化的处理，PNN 模型定义的内积和外积操作显然更有针对性地强调了不同特征之间的 交互，从而让模型更容易捕获特征的交叉信息\n",
    "- 缺点：所有特征进 行无差别的交叉，在一定程度上忽略了原始特征向量中包含的有价值信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640acd2",
   "metadata": {},
   "source": [
    "## Wide & Deep模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1cd7d",
   "metadata": {},
   "source": [
    "**记忆能力和泛化能力的综合**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1a693",
   "metadata": {},
   "source": [
    "- wide: 记忆能力\n",
    "- deep: 泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c21faa",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.10.26](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011910853.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d351318",
   "metadata": {},
   "source": [
    "Wide&Deep模型把单输入层的Wide部分与由Embedding层和多隐 层组成的Deep部分连接起来，一起输入最终的输出层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0197d",
   "metadata": {},
   "source": [
    "- 单层的Wide部分善于处理大量稀疏的 id类特征\n",
    "- Deep部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb25bc8",
   "metadata": {},
   "source": [
    "Wide&Deep 模型的输入：\n",
    "- Deep 部分的输入是全量的特征向量，包括用户年龄(Age)、已安装应用数量(App Installs)、设备类型(Device Class)、已安装 应用(User Installed App)、曝光应用(Impression App)等特征\n",
    "- Wide 部分的输入仅仅是已安装应用和曝光应用两类特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac1888",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.21.03](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011921581.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c3b7c",
   "metadata": {},
   "source": [
    "wide:融合特征使用 **交叉积变换函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f2550",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.33.28](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011933500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbb109",
   "metadata": {},
   "source": [
    "## Deep & Cross模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56241ab9",
   "metadata": {},
   "source": [
    "在 Wide&Deep 模型之后，有越 来越多的工作集中于分别改进Wide&Deep模型的Wide部分或是Deep部 分。较典型的工作是2017年由斯坦福大学和谷歌的研究人员提出的Dee p&Cross模型(简称DCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65b276",
   "metadata": {},
   "source": [
    "**Cross部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87814001",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.35.56](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011935442.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5973390",
   "metadata": {},
   "source": [
    "设计Cross网络的目的是增加特征之间的交互力度，使用多层交叉 层(Cross layer)对输入向量进行特征交叉。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada389c7",
   "metadata": {},
   "source": [
    "**第 L 层到第 L+1 层**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fed96f",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.40.31](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011940246.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca357d",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 19.43.17](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207011943322.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599a8ae",
   "metadata": {},
   "source": [
    "## FM与深度学习融合\n",
    "## FNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394e86f",
   "metadata": {},
   "source": [
    "从稀疏输入向量到稠密向量的转换过程也是经典的 Embedding 层的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7580c",
   "metadata": {},
   "source": [
    "![](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012039289.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ed20f",
   "metadata": {},
   "source": [
    "Embedding层的作用是将稀疏输入向量转换成 稠密向量，但Embedding层的存在往往会拖慢整个神经网络的收敛速度，原因有两个：\n",
    "- Embedding层的参数数量巨大\n",
    "- 由于输入向量过于稀疏，在随机梯度下降的过程中，只有与非零特征相连的 Embedding 层权重会被更新，这进一步降低了Embedding层的收敛速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed22729",
   "metadata": {},
   "source": [
    "**FM模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee8c58",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 20.45.07](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012045072.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca0e2d",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 20.47.25](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012047102.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d96ac",
   "metadata": {},
   "source": [
    "FNN 模型除了可以使用 FM 参数初始化 Embedding 层权重，也为 另一种Embedding 层的处理方式——Embedding 预训练提供了借鉴思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0c5aa",
   "metadata": {},
   "source": [
    "#### 总结\n",
    "**FNN把FM的训练结果作为初始化权重，并没有对神经网络的结构 进行调整**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03939f2",
   "metadata": {},
   "source": [
    "## DeepFM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4093d6a",
   "metadata": {},
   "source": [
    "DeepFM对Wide&Deep模型的改进之处在于，它用 FM 替换了原来的 Wide 部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45bdcb",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 21.04.37](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012104148.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88137801",
   "metadata": {},
   "source": [
    "改进：\n",
    "- 左边的FM部分与右边的深度神经网络部分共享相同的Embedding层\n",
    "- 左侧的FM部分对不同的特征域的 Embedding 进行了两两交叉，也就是将Embedding向量当作原 FM 中的特征隐向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5154b6",
   "metadata": {},
   "source": [
    "## NFM模型\n",
    "FM进行神经网络化尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5b8f4",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 21.16.48](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012116649.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fe9cb",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 21.16.13](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012116479.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f055f",
   "metadata": {},
   "source": [
    "**NFM 网络架构的特点非常明显，就是在 Embedding 层和多层神经 网络之间加入特征交叉池化层**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315512bb",
   "metadata": {},
   "source": [
    "![截屏2022-07-01 21.19.54](https://ghproxy.com/https://github.com/Maserhe/PIc-Bed/blob/master/typora/202207012121109.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45069dfb",
   "metadata": {},
   "source": [
    "在进行两两Embedding向量的元素积操作后，对交叉特征向量取 和，得到池化层的输出向量。再把该向量输入上层的多层全连接神经 网络，进行进一步的交叉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750167cf",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c157d",
   "metadata": {},
   "source": [
    "FNN、DeepFM、NFM三个结合FM思路的深度学习模 型。它们的特点都是在经典多层神经网络的基础上加入有针对性的特 征交叉操作，让模型具备更强的非线性表达能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924620dd",
   "metadata": {},
   "source": [
    "沿着特征工程自动化的思路，深度学习模型从 PNN 一路走来，经 过了Wide&Deep、Deep&Cross、FNN、DeepFM、NFM等模型，进行 了大量的、基于不同特征互操作思路的尝试。但特征工程的思路走到 这里几乎已经穷尽了可能的尝试，模型进一步提升的空间非常小，这 也是这类模型的局限性所在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67b76a",
   "metadata": {},
   "source": [
    "## 注意力机制在推荐模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4925411",
   "metadata": {},
   "source": [
    "**影响较大的模型**\n",
    "- AFM 浙大\n",
    "- DIN 阿里巴巴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70f878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
